# Data Scientist | Data Engineer
[![LinkedIn](https://img.shields.io/badge/LinkedIn-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/abhinav51/)      [![GitHub](https://img.shields.io/badge/GitHub-black?style=for-the-badge&logo=github)](https://github.com/anehra-15/)

#### **About Me :** With 3.5+ years of industry experience in cloud infrastructure and data engineering, I bring a solid foundation in building and optimizing data pipelines, managing large datasets, and implementing scalable solutions using Big data tech stack and technologies like Python, Spark, AWS, and SQL etc. I'm passionate about the Data Science and Engineering field and their applications in generating valuable insights from messy and large datasets. Imagine a puzzle — I love piecing together information from chaotic datasets to reveal the big picture and unlock valuable insights!

#### **Technical Skills:** Kafka, Airflow, AWS S3, Apache Spark, Scala, Autosys, CyberArk, Sqoop, Hive, HDFS, Confluence, WebLogic, Big Data, Python, Linux, MySQL, Shell Scripting, IBM Connect Direct (NDM), ServiceNow, R Programming, Data Mining, SQL, Apache Iceberg, Presto, Deeque, Docker, ArgoCD, AWS, Intellij, Git, Bitbucket, JIRA, Maven, PySpark

## Certifications					       		
- AWS Certified Cloud Practitioner
- Spark Framework- Infosys
- Oracle Cloud Infrastructure foundations 2021 Certified Associate- Oracle
- Big Data 101- Infosys
- Infosys Certified Python Associate- Infosys
- Apache Kafka Tutorials- Infosys Springboard
  
## Education					       		
- M.S, Engineering Science - Data Science, GPA: 3.67/4.0	| University at Buffalo, Buffalo, NY, USA      		
- B.Tech, Software Engineering, CGPA: 8.04/10 | SRM Institute of Science and Technology, India 

## Work Experience
**Data Engineer @ Saayam For All (Buffalo, NY)(_Feb 2025 - Present_)**
- **Skills**: Python (Programming Language) · Application Programming Interfaces (API) · Data Extraction · Extract, Transform, Load (ETL) · Requests · Beautiful Soup · JSON

**Associate Cloud Pipeline Engineer @ Calix (San Jose, CA)(_Oct 2024 - Nov 2024_)**
- Developed and integrated advanced data quality checks, including custom metrics like Bad Email Check, Completeness with Threshold, and IsEmpty validation, significantly reducing manual oversight, enhancing data accuracy and ensuring compliance with business rules.
- **Skills**: Spark, Scala, PySpark, Data Quality, Amazon Deeque, Azkaban, Apache Iceberg, DynamoDB, S3, Data Governance, CDC

**Cloud Data Pipeline Intern @ Calix (San Jose, CA)(_May 2024 - Aug 2024_)**
- Developed a highly scalable Spark-based SDK, leveraging distributed processing to significantly accelerate data encryption and decryption tasks by Transitioning from a REST API to a Spark-based SDK, directly contributing to improved compliance and operational efficiency.
-  Led a successful PoC to evaluate Apache Iceberg's compatibility with our data lake, focusing on optimizing data management for scalability and performance.
-  Integrated Apache Iceberg into the data lake to support incremental data loads alongside existing full loads, ensuring seamless handling of complex data operations like inserts, updates, and deletes.
- **Skills**: Spark, Scala, PySpark, SDK, Apache Iceberg, DynamoDB, S3, Presto
  
**Technology Analyst - Data Engineer (Former Senior Systems Engineer) @ Infosys Pvt Ltd (_Jan 2020 - Jul 2023_)**
- Lead real-time data validation efforts using Apache Spark and advanced SQL techniques, ensuring strict adherence to SLAs for seamless data processing.
- Automated data import processes through Shell scripting, Airflow, and Sqoop, resulting in a significant reduction in manual efforts and enhanced operational efficiency.
- Architected seamless integration among Hive, Hbase, and Spark for agile data analysis and swift retrieval, optimizing complex operations.
- Developed and implemented strategies to optimize data querying efficiency, including Hive table management, partitioning, and incremental imports.
- Consistently exceeded client expectations, delivering exceptional results and maintaining a high standard of service delivery.
- Spearheaded configuration and troubleshooting of IBM Connect Direct/NDM connectivity, ensuring smooth data exchange across multiple partner systems.
- Managed end-to-end setup of Linux-based environments supporting Oracle Revenue Management and Billing (ORMB) applications across various instances (DEV/SIT/UAT/PTE/PROD/COB).
- Drove automation initiatives using shell scripts and Ansible playbooks, significantly reducing delivery time.
- Facilitated enhanced password management through the onboarding of database FIDs to CyberArk.
- Proficiently handled VM procurement, middleware application server setup, and system instance management.



## Projects
### [DocuChat AI – Interactive Q&A Assistant](https://github.com/anehra-15/Docuchat-AI)

![alt text](img/port.jpg)

### [Advanced Predictive Modelling in Healthcare Data Analytics for Early Disease Detection and Proactive Medical Intervention](https://github.com/anehra-15/-Predictive-Modelling-for-Early-Disease-Detection-)

![alt text](img/p2.jpg)

### [Loan Approval Predictor](https://github.com/anehra-15/Bank-Loan-Approval-Predictor)

![alt text](img/p3.jpg)

### [Music Streaming Application Data ETL Pipeline using Python and AWS](https://github.com/anehra-15/Music_Data_ETL_Pipeline)

![alt text](img/etl.jpg)

### [E-commerce Data Extraction with Python](https://github.com/anehra-15/E_commerce_Data_Extraction_with_Python)

![alt text](img/d_e.PNG)



